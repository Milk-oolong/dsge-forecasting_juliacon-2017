{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using Parallel Computing for Macroeconomic Forecasting at the Federal Reserve Bank of New York\n",
    "\n",
    "**Pearl Li** (@pearlzli) <br>\n",
    "**Federal Reserve Bank of New York** (@FRBNY-DSGE)\n",
    "\n",
    "June 21, 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Disclaimer\n",
    "\n",
    "This talk reflects the experience of the author and does not represent an endorsement by the Federal Reserve Bank of New York or the Federal Reserve System of any particular product or service. The views expressed in this talk are those of the authors and do not necessarily reflect the position of the Federal Reserve Bank of New York or the Federal Reserve System. Any errors or omissions are the responsibility of the authors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "\n",
    "1. Overview of DSGE modeling\n",
    "2. \"The forecast step\": objectives and challenges\n",
    "3. Parallelizing the forecast code: <br>\n",
    "   a. DistributedArrays.jl <br>\n",
    "   b. `pmap` and blocking\n",
    "4. Conclusion and next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview of DSGE modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A DSGE (dynamic stochastic general equilibrium) model is a \"micro-founded macro-model\", used in both policy and academia for\n",
    "\n",
    "- Forecasting macroeconomic variables (GDP growth, inflation, interest rate, ...)\n",
    "- Understanding the forces underlying past economic outcomes\n",
    "- Analyzing the effect of monetary policy\n",
    "- Investigating counterfactuals or alternative scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let\n",
    "\n",
    "- $\\theta$ be a vector of parameters (discount rate, capital share, ...)\n",
    "- $s_t$ be a vector of latent states (output growth, natural rate of interest, ...), including expectations of future states and lags\n",
    "- $\\epsilon_t$ be a vector of exogenous shocks (productivity shock, ...)\n",
    "- $\\eta_t$ be a vector of expectational errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We express the evolution of the system over time in terms of **equilibrium conditions** (derived from micro theory)\n",
    "\n",
    "$$\\Gamma_0(\\theta) s_t = \\Gamma_1(\\theta) s_{t-1} + \\Psi(\\theta) \\epsilon_t + \\Pi(\\theta) \\eta_t + C(\\theta)$$\n",
    "$$\\epsilon_t \\sim N(0, Q(\\theta))$$\n",
    "\n",
    "which are solved to give the **transition equation**\n",
    "\n",
    "$$s_t = T(\\theta) s_{t-1} + R(\\theta) \\epsilon_t + C(\\theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let $y_t$ be a vector of observed variables (real GDP growth, core PCE inflation, ...). We map latent states $s_t$ to observables $y_t$ using the **measurement equation**\n",
    "\n",
    "$$y_t = Z(\\theta) s_t + D(\\theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "DSGE.jl centers around a **model object**\n",
    "\n",
    "- Each model is a concrete subtype of `AbstractModel`\n",
    "- Model object stores information about parameters, states, observables, computational settings, and more\n",
    "- Use **method dispatch** to define model-specific functions:\n",
    "  + e.g. returning equilibrium condition matrices $\\Gamma_0$, $\\Gamma_1$, $\\Psi$, $\\Pi$, and $C$ for a particular model (`eqcond`)\n",
    "- Model-agnostic methods are defined for `AbstractModels`: e.g. `estimate`, `forecast_one`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We are interested in\n",
    "\n",
    "- Sampling from the posterior distribution $\\mathbb{P}(\\theta | y_{1:T})$ of the parameters $\\theta$ (**estimation step**)\n",
    "- Using the estimated parameter draws to forecast, compute impulse responses and shock decompositions, and more (**forecast step**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## \"The forecast step\": objectives and challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the estimation step, we generated a large number of parameter draws from their posterior distribution. For each draw $\\theta^{(j)}$, we might want to compute the following *products*:\n",
    "\n",
    "- **Smoothed history:** Estimate smoothed states $s_{t|T}$ (where $T$ is the last data period and $t < T$)\n",
    "- **Forecast:** Iterate the state space forward to get future states $s_{T+h|T}$\n",
    "- **Shock decomposition:** Decompose $s_{t|T}$ into a weighted sum of accumulated shocks $\\epsilon^{(i)}_{1:t|T}$ (where $i$ indexes the particular shock, e.g. productivity)\n",
    "- **Impulse response:** Compute $\\frac{\\partial s_{1:H}}{\\partial \\epsilon^{(i)}_1}$, the response of states to a shock $\\epsilon^{(i)}$ at time 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Additional objectives\n",
    "\n",
    "- Repeat for large number of draws (typically 20,000)\n",
    "- Interested not only in states, but other *classes*:\n",
    "  + Shocks\n",
    "  + Observables\n",
    "  + Other unobserved linear combinations of states (\"pseudo-observables\")\n",
    "- With and without conditioning on different nowcasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Challenges\n",
    "\n",
    "1. Minimize computational time\n",
    "   + \"Whole shebang\" (three conditional types, all products) took ~70 minutes using our MATLAB code\n",
    "<br>\n",
    "2. Use reasonable amount of memory\n",
    "   + (e.g. for computing smoothed historical states) 229 quarters $\\times$ 84 states $\\times$ 20,000 draws $\\times$ 3 conditional types\n",
    "   + Shock decompositions and impulse responses add another dimension!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "for cond_type in [:none, :full, :semi]\n",
    "    for θ_j in parameter_draws\n",
    "        # Compute state space matrices under θ_j\n",
    "        update!(model, θ_j)\n",
    "        system = compute_system(model)\n",
    "        \n",
    "        # Filter and smooth historical states\n",
    "        kal = filter(model, data, system)\n",
    "        histstates, histshocks, histpseudo, s_T = \n",
    "            smooth(model, data, system, kal)\n",
    "        \n",
    "        # Forecast from s_T\n",
    "        forecaststates, forecastobs, forecastpseudo, forecastshocks = \n",
    "            forecast(model, system, s_T)\n",
    "        \n",
    "        # Decompose history and forecast into shocks\n",
    "        shockdecstates, shockdecobs, shockdecpseudo = \n",
    "            shock_decompositions(model, system, histshocks)\n",
    "        \n",
    "        # Compute impulse response functions\n",
    "        irfstates, irfobs, irfpseudo = impulse_responses(model, system)\n",
    "        \n",
    "        # Write forecast outputs\n",
    "        write_forecast_outputs(...)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallelizing the forecast code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Preview of results: benchmark times against MATLAB (smaller is better)\n",
    "\n",
    "| Test                                     | MATLAB (2014a) | Julia (0.4.5) |\n",
    "| ---------------------------------------- | -------------- | ------------- |\n",
    "| Smoothing                                | 1.00           | 0.38          |\n",
    "| Forecasting                              | 1.00           | 0.24          |\n",
    "| Computing shock decompositions           | 1.00           | 0.12          |\n",
    "| All forecast outputs (modal parameters)  | 1.00           | 0.10          |\n",
    "| All forecast outputs (full distribution) | 1.00*          | 0.22          |\n",
    "\n",
    "*Run in MATLAB 2009a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Two approaches considered\n",
    "\n",
    "1. Distributed storage, i.e. using [DistributedArrays.jl](https://github.com/JuliaParallel/DistributedArrays.jl)\n",
    "2. `pmap` and \"blocking\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "DistributedArrays.jl\n",
    "\n",
    "- Solution for storing arrays too large for one machine\n",
    "- `DArray` storage distributed across multiple processes\n",
    "- Each process operates on the part of the array it owns $\\implies$ natural parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module DistributedArrays.\n",
      "WARNING: replacing module DistributedArrays.\n",
      "WARNING: replacing module DistributedArrays.\n",
      "WARNING: replacing module DistributedArrays.\n",
      "WARNING: replacing module DistributedArrays.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6-element Array{Symbol,1}:\n",
       " :identity\n",
       " :dims    \n",
       " :pids    \n",
       " :indexes \n",
       " :cuts    \n",
       " :release "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add processes and load package on all processes\n",
    "worker_procs = addprocs(5)\n",
    "@everywhere using DistributedArrays\n",
    "\n",
    "# Initialize DArray, distributing along the first dimension across all \n",
    "# 5 processes\n",
    "arr_size = (25, 2, 2)\n",
    "arr_div  = [5, 1, 1]\n",
    "arr = drand(arr_size, worker_procs, arr_div)\n",
    "fieldnames(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1:5,1:2,1:2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query a worker process for its local indices into arr\n",
    "worker_id = worker_procs[1]\n",
    "remotecall_fetch(localindexes, worker_id, arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×2×2 Array{Float64,3}:\n",
       "[:, :, 1] =\n",
       " 0.481367   0.592673 \n",
       " 0.532853   0.240059 \n",
       " 0.0213235  0.0850404\n",
       " 0.568293   0.015669 \n",
       " 0.850455   0.0651117\n",
       "\n",
       "[:, :, 2] =\n",
       " 0.71181   0.512633 \n",
       " 0.390442  0.809272 \n",
       " 0.140688  0.953632 \n",
       " 0.34935   0.65508  \n",
       " 0.420469  0.0855251"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return worker's local array\n",
    "remotecall_fetch(localpart, worker_id, arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":ok"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove worker processes\n",
    "rmprocs(worker_procs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Using `DArrays` in the forecast step\n",
    "\n",
    "- Distribute parameter draws among worker processes\n",
    "- Each process will compute all outputs for the draws it owns\n",
    "- Use both:\n",
    "  + Lower-level functions (e.g. `smooth`) which operate on one draw\n",
    "  + Higher-level functions (`smooth_all`) which, given many draws, call lower-level function on each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "worker_procs = addprocs(50)\n",
    "\n",
    "# Load draws and compute systems for each draw\n",
    "parameter_draws = load_draws(model, worker_procs) # returns a DArray{Float64, 3}\n",
    "systems = prepare_systems(model, parameter_draws) # returns a DArray{System, 1}\n",
    "\n",
    "# Filter and smooth historical states\n",
    "# Both filter_all and smooth_all return DArrays\n",
    "kals = filter_all(model, data, systems)\n",
    "histstates, histshocks, histpseudo, s_Ts =\n",
    "    smooth_all(model, data, systems, kals; procs = worker_procs)\n",
    "\n",
    "# Write forecast outputs\n",
    "write_forecast_outputs(...)\n",
    "\n",
    "...\n",
    "\n",
    "rmprocs(worker_procs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Disadvantage #1: draw assignment \n",
    "\n",
    "- Must explicitly assign draws to processes\n",
    "- `DArray`s must be divided equally among processes\n",
    "- What if number of draws isn't divisible by number of processes? Have to throw out remainder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Disadvantage #2: unwieldy `DArray` construction\n",
    "\n",
    "- Specify `init` function mapping a tuple of local indices to the local part of the array\n",
    "- Can only initialize one `DArray` for each call to the `init` function\n",
    "- But what we want for `smooth_all` is to return four `DArray`s: `histstates`, `histshocks`, `histpseudo`, and `s_Ts`\n",
    "- Result: ugly code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize one big DArray with all outputs\n",
    "out = DArray((ndraws, nstates + nshocks + npseudo + 1, nperiods), \n",
    "             procs, [nprocs, 1, 1]) do I\n",
    "    \n",
    "    # Initialize local part of array\n",
    "    localpart = zeros(map(length, I)...)\n",
    "    \n",
    "    # Determine which draws i belong to this process\n",
    "    draw_inds = first(I)\n",
    "    ndraws_local = length(draw_inds)\n",
    "\n",
    "    for i in draw_inds\n",
    "        # Call smooth on draw i \n",
    "        states, shocks, pseudo, s_T = smooth(model, data, systems[i], kals[i])\n",
    "\n",
    "        # Compute index of draw i into local array\n",
    "        i_local = mod(i-1, ndraws_local) + 1\n",
    "\n",
    "        # Assign smooth outputs to local array\n",
    "        localpart[i_local, states_range,  :] = states\n",
    "        localpart[i_local, shocks_range,  :] = shocks\n",
    "        localpart[i_local, pseudo_range,  :] = pseudo\n",
    "        localpart[i_local, statesT_range, states_range] = s_T\n",
    "    end\n",
    "        \n",
    "    return localpart    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Convert SubArrays to DArrays\n",
    "states = convert(DArray, out[1:ndraws, states_range, 1:nperiods])\n",
    "shocks = convert(DArray, out[1:ndraws, shocks_range, 1:nperiods])\n",
    "pseudo = convert(DArray, out[1:ndraws, pseudo_range, 1:nperiods])\n",
    "s_Ts = DArray((ndraws,), procs, [nprocs]) do I\n",
    "    Vector{S}[convert(Array, slice(out, i, statesT_range, states_range)) for i in first(I)]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Figure 1: `smooth_all` result before indexing out `SubArray`s\n",
    "\n",
    "![DArray result](figure1.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Could instead construct `out` as a `DArray` of `Tuple{Matrix{Float64}, Matrix{Float64}, Matrix{Float64}, Vector{Float64}}` types $\\implies$ streamline `init` function\n",
    "- However, this just postpones unpacking `out`\n",
    "- Eventually want `histstates` as a 3-dimensional array (draws $\\times$ states $\\times$ time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Disadvantage #3: computational time\n",
    "\n",
    "- Parameter draws live on the processes they've been assigned to; difficult to reallocate\n",
    "- Sometimes some compute nodes are busier than others\n",
    "- Bottleneck effect: since `filter_all` must return before `smooth_all` can begin, proceeding is limited by compute time of **slowest process**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`pmap` + blocking\n",
    "\n",
    "- Divide parameter draws into \"blocks\" (typically 20,000 draws into 20 blocks)\n",
    "- Read in one block at a time\n",
    "- For each block, parallel map `forecast_one_draw` (computes all forecast outputs for a single draw) over that draw's parameters\n",
    "- When `pmap` returns, write current block's results to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Get indices of draws corresponding to each block\n",
    "block_indices = forecast_block_inds(model)\n",
    "nblocks = length(block_indices)\n",
    "\n",
    "for block = 1:nblocks\n",
    "    # Load draws for this block\n",
    "    parameter_draws = load_draws(model, block)\n",
    "\n",
    "    # Compute forecast outputs for each draw in block\n",
    "    forecast_outputs = pmap(θ_j -> forecast_one_draw(m, θ_j, data),\n",
    "                            parameter_draws)\n",
    "\n",
    "    # Write results for this block\n",
    "    write_forecast_outputs(model, forecast_outputs, block_number = block)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "function forecast_one_draw(model::AbstractModel, θ_j::Vector{Float64},\n",
    "                           data::Matrix{Float64})\n",
    "    # Compute state space matrices under θ_j\n",
    "    update!(model, θ_j)\n",
    "    system = compute_system(model)\n",
    "    \n",
    "    # Filter and smooth historical states\n",
    "    kal = filter(model, data, system)\n",
    "    histstates, histshocks, histpseudo, s_T = \n",
    "        smooth(model, data, system, kal)\n",
    "        \n",
    "    # Forecast from s_T\n",
    "    forecaststates, forecastobs, forecastpseudo, forecastshocks = \n",
    "        forecast(model, system, s_T)\n",
    "        \n",
    "    # Decompose history and forecast into shocks\n",
    "    shockdecstates, shockdecobs, shockdecpseudo = \n",
    "        shock_decompositions(model, system, histshocks)\n",
    "      \n",
    "    # Compute impulse response functions\n",
    "    irfstates, irfobs, irfpseudo = impulse_responses(model, system)\n",
    "    \n",
    "    # Assign results to dictionary to be returned\n",
    "    forecast_outputs = Dict{Symbol, Array{Float64}}()\n",
    "    ...\n",
    "    return forecast_outputs\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Advantages\n",
    "\n",
    "- `pmap` handles assigning draws to worker processes automatically (`DArray`s disadvantage #1)\n",
    "- Don't need to implement functions like `smooth_all` which handle multiple draws (disadvantage #2)\n",
    "- Takes advantage of independence of draws (disadvantage #3)\n",
    "- Computing in blocks reduces memory usage when `pmap` returns results to originator process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Why not `@parallel for`? Per [Julia documentation](https://docs.julialang.org/en/stable/manual/parallel-computing/#parallel-map-and-loops):\n",
    "\n",
    "> Julia’s `pmap()` is designed for the case where each function call does a large amount of work. In contrast, `@parallel for` can handle situations where each iteration is tiny, perhaps merely summing two numbers.\n",
    "\n",
    "Also, can't assign to a dictionary using `@parallel for` because each process will have a separate copy of it. (Docs recommend using `SharedArray`s to get around this.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Take advantage of [writing to a subset](https://github.com/JuliaIO/HDF5.jl/blob/master/doc/hdf5.md#reading-and-writing-data) of an HDF5 dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "function write_forecast_block(file::JldFile, arr::Array{Float64}, \n",
    "                              block_indices::Range{Int})\n",
    "\n",
    "    # Access JLD file's underlying HDF5 file\n",
    "    pfile = file.plain\n",
    "    \n",
    "    # Get reference to existing HDF5 dataset named \"arr\"\n",
    "    dataset = HDF5.d_open(pfile, \"arr\")\n",
    "    \n",
    "    # Write to subset of dataset corresponding to given block indices\n",
    "    ndims = length(size(dataset))\n",
    "    dataset[block_indices, fill(Colon(), ndims-1)...] = arr\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Result: more natural, readable, efficient, and **beautiful** code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conclusion and next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Challenges for us moving forward\n",
    "\n",
    "- Make DSGE.jl less us-specific\n",
    "- Move to Julia 0.6 and 1.0\n",
    "- Be responsible contributors to the Julia package ecosystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ongoing work\n",
    "\n",
    "- Forecasting under alternative monetary policy rules\n",
    "- Forecast evaluation and decomposing changes in forecasts\n",
    "- Estimating nonlinear models using the [tempered particle filter](https://web.sas.upenn.edu/schorf/files/2016/10/HS-TemperedParticleFilter-PaperAppendix-1mlvlvu.pdf) (Herbst & Schorfheide 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Future work\n",
    "\n",
    "- Forecasting conditional on alternative scenarios\n",
    "- Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Acknowledgments\n",
    "\n",
    "- New York Fed DSGE team:\n",
    "  + Marco Del Negro, Marc Giannoni, Abhi Gupta, Erica Moszkowski, Sara Shahanaghi, Micah Smith\n",
    "\n",
    "- QuantEcon collaborators:\n",
    "  + Zac Cranko, Spencer Lyon, John Stachurski, Pablo Winant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Thank you! Questions?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
